{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e722d7",
   "metadata": {
    "papermill": {
     "duration": 0.008156,
     "end_time": "2022-12-19T16:24:39.062721",
     "exception": false,
     "start_time": "2022-12-19T16:24:39.054565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training a Convolutional Neural Network for digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681477b1",
   "metadata": {
    "papermill": {
     "duration": 0.006584,
     "end_time": "2022-12-19T16:24:39.076583",
     "exception": false,
     "start_time": "2022-12-19T16:24:39.069999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This was built following a tutorial in the wonderful book *Machine Learning with PyTorch and Scikit-Learn* by Raschka, Liu and Mirjalili (2022, Packt Publishing).  In this notebook, we do the following:\n",
    "\n",
    "1. Use the PyTorch library (https://pytorch.org/) to construct and train a convolutional neural network (CNN) on the MNIST handwritten digit database (http://yann.lecun.com/exdb/mnist%7D).\n",
    "2. Create a Kaggle submission of our predictions.\n",
    "3. As a bonus, deploy the trained model as an interactive web app using the Gradio library (https://gradio.app/).\n",
    "\n",
    "Note that the Gradio app can be found by visiting my huggingface page: https://huggingface.co/spaces/etweedy/digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6c4ca",
   "metadata": {
    "papermill": {
     "duration": 0.006742,
     "end_time": "2022-12-19T16:24:39.090323",
     "exception": false,
     "start_time": "2022-12-19T16:24:39.083581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcc0c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:39.107088Z",
     "iopub.status.busy": "2022-12-19T16:24:39.105936Z",
     "iopub.status.idle": "2022-12-19T16:24:41.644505Z",
     "shell.execute_reply": "2022-12-19T16:24:41.643332Z"
    },
    "papermill": {
     "duration": 2.549474,
     "end_time": "2022-12-19T16:24:41.647079",
     "exception": false,
     "start_time": "2022-12-19T16:24:39.097605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65280cdd",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2022-12-19T16:24:41.660629",
     "exception": false,
     "start_time": "2022-12-19T16:24:41.654085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and the MNIST dataset and create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babd338f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:41.678004Z",
     "iopub.status.busy": "2022-12-19T16:24:41.676405Z",
     "iopub.status.idle": "2022-12-19T16:24:46.708135Z",
     "shell.execute_reply": "2022-12-19T16:24:46.707128Z"
    },
    "papermill": {
     "duration": 5.042026,
     "end_time": "2022-12-19T16:24:46.710625",
     "exception": false,
     "start_time": "2022-12-19T16:24:41.668599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train,df_val = train_test_split(df,test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f955f0",
   "metadata": {
    "papermill": {
     "duration": 0.006617,
     "end_time": "2022-12-19T16:24:46.724560",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.717943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now create a custom PyTorch Dataset child class called MNISTDataset, which we will use to process our DataFrames into PyTorch tensors.  The __getitem__ method either:\n",
    "* if is_test=False, returns just the image as a numpy array of shape (28,28) with greyscale pixel values in [0,255]\n",
    "* if is_test=True, returns that image numpy array as well as the ground truth label as an integer in [0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0fd0db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:46.740498Z",
     "iopub.status.busy": "2022-12-19T16:24:46.739035Z",
     "iopub.status.idle": "2022-12-19T16:24:46.746894Z",
     "shell.execute_reply": "2022-12-19T16:24:46.746046Z"
    },
    "papermill": {
     "duration": 0.017753,
     "end_time": "2022-12-19T16:24:46.748993",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.731240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data,transform=None, is_test=False):\n",
    "        super().__init__()\n",
    "        self.dataset = data\n",
    "        self.transform=transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset.iloc[index].to_numpy()\n",
    "        label = data[0]                             #il faut dire ce qui est le Y et ce qui est le X pour chaque ligne \n",
    "        image = data[1:].reshape(28, 28)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image.astype(np.float32))\n",
    "        return image, label\n",
    "  \n",
    "    # def __getitem__(self, index):\n",
    "    #     if self.is_test:\n",
    "    #         data = self.dataset.iloc[index].to_numpy()\n",
    "    #         image = data.reshape(28, 28)/255\n",
    "    #         label = None\n",
    "    #     else:\n",
    "    #         data = self.dataset.iloc[index].to_numpy()\n",
    "    #         label = data[0]\n",
    "    #         image = data[1:].reshape(28, 28)/255\n",
    "    #     if self.transform is not None:\n",
    "    #         image = self.transform(image.astype(np.float32))\n",
    "    #     return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d1833",
   "metadata": {
    "papermill": {
     "duration": 0.006535,
     "end_time": "2022-12-19T16:24:46.762113",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.755578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we will define a transform for the Dataset class to use, which will be a composition of:\n",
    "1. Converstion from numpy array to PIL image file using ToPILImage, then\n",
    "2. Conversion to a PyTorch tensor using ToTensor().  Note that ToTensor() automatically rescales the pixel values in [0,255] to [0,1] so we needn't do that separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf41b2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:46.776795Z",
     "iopub.status.busy": "2022-12-19T16:24:46.776520Z",
     "iopub.status.idle": "2022-12-19T16:24:46.780959Z",
     "shell.execute_reply": "2022-12-19T16:24:46.779927Z"
    },
    "papermill": {
     "duration": 0.014356,
     "end_time": "2022-12-19T16:24:46.783136",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.768780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "transform = transforms.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1c46bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:46.797525Z",
     "iopub.status.busy": "2022-12-19T16:24:46.797266Z",
     "iopub.status.idle": "2022-12-19T16:24:46.801883Z",
     "shell.execute_reply": "2022-12-19T16:24:46.800957Z"
    },
    "papermill": {
     "duration": 0.014012,
     "end_time": "2022-12-19T16:24:46.803858",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.789846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ds_train = MNISTDataset(df_train,transform = transform)\n",
    "ds_val = MNISTDataset(df_val,transform=transform)\n",
    "ds_test = MNISTDataset(df_test,transform = transform, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97a528b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:46.818203Z",
     "iopub.status.busy": "2022-12-19T16:24:46.817952Z",
     "iopub.status.idle": "2022-12-19T16:24:46.824907Z",
     "shell.execute_reply": "2022-12-19T16:24:46.824054Z"
    },
    "papermill": {
     "duration": 0.016422,
     "end_time": "2022-12-19T16:24:46.826930",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.810508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "torch.manual_seed(1)\n",
    "dl_train = DataLoader(ds_train,batch_size,shuffle=True)\n",
    "dl_val = DataLoader(ds_val,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f99ae4",
   "metadata": {
    "papermill": {
     "duration": 0.006467,
     "end_time": "2022-12-19T16:24:46.839980",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.833513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Construct CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d506b",
   "metadata": {
    "papermill": {
     "duration": 0.006398,
     "end_time": "2022-12-19T16:24:46.853100",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.846702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We build a CNN with two convolutive layers with batch normalization, ReLU activation, and 2x2 max-pooling, followed by a flattening layer and two linear layers with a dropout layer between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdc7424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:46.867643Z",
     "iopub.status.busy": "2022-12-19T16:24:46.867395Z",
     "iopub.status.idle": "2022-12-19T16:24:49.377658Z",
     "shell.execute_reply": "2022-12-19T16:24:49.376617Z"
    },
    "papermill": {
     "duration": 2.520128,
     "end_time": "2022-12-19T16:24:49.379849",
     "exception": false,
     "start_time": "2022-12-19T16:24:46.859721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv2d(\n",
    "        in_channels=1,out_channels=32,\n",
    "        kernel_size=5,padding=2\n",
    "    ),\n",
    ")\n",
    "model.add_module('bn1',nn.BatchNorm2d(32))\n",
    "model.add_module('relu1',nn.ReLU())\n",
    "model.add_module('pool1',nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module(\n",
    "    'conv2',\n",
    "    nn.Conv2d(\n",
    "        in_channels=32,out_channels=64,\n",
    "        kernel_size=5,padding=2\n",
    "    ),\n",
    ")\n",
    "model.add_module('bn2',nn.BatchNorm2d(64))\n",
    "model.add_module('relu2',nn.ReLU())\n",
    "model.add_module('pool2',nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module('flatten',nn.Flatten())\n",
    "model.add_module('fc1',nn.Linear(3136,1024))\n",
    "model.add_module('dropout',nn.Dropout(p=0.5))\n",
    "model.add_module('fc2',nn.Linear(1024,10))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6a4df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:49.395554Z",
     "iopub.status.busy": "2022-12-19T16:24:49.394768Z",
     "iopub.status.idle": "2022-12-19T16:24:49.399739Z",
     "shell.execute_reply": "2022-12-19T16:24:49.398815Z"
    },
    "papermill": {
     "duration": 0.014853,
     "end_time": "2022-12-19T16:24:49.401795",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.386942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(),lr=0.0015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567e69b",
   "metadata": {
    "papermill": {
     "duration": 0.006625,
     "end_time": "2022-12-19T16:24:49.415123",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.408498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a049b82",
   "metadata": {
    "papermill": {
     "duration": 0.006655,
     "end_time": "2022-12-19T16:24:49.428569",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.421914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now construct our training function, which keeps track of training loss and accuracy and validation loss and accuracy after each epoch.  Accuracy values are printed as we progress through training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9632108b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:49.443853Z",
     "iopub.status.busy": "2022-12-19T16:24:49.443094Z",
     "iopub.status.idle": "2022-12-19T16:24:49.453212Z",
     "shell.execute_reply": "2022-12-19T16:24:49.452387Z"
    },
    "papermill": {
     "duration": 0.019746,
     "end_time": "2022-12-19T16:24:49.455124",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.435378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model,num_epochs,dl_train,dl_val):\n",
    "    loss_hist_train = [0]*num_epochs\n",
    "    acc_hist_train = [0]*num_epochs\n",
    "    loss_hist_val = [0]*num_epochs\n",
    "    acc_hist_val = [0]*num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch,y_batch in dl_train:\n",
    "            x_batch=x_batch.to(device)\n",
    "            y_batch=y_batch.to(device)\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred,y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct=(torch.argmax(pred,dim=1) == y_batch).float()\n",
    "            acc_hist_train[epoch] += is_correct.sum()\n",
    "            \n",
    "        loss_hist_train[epoch] /= len(dl_train.dataset)\n",
    "        acc_hist_train[epoch] /= len(dl_train.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for x_batch,y_batch in dl_val:\n",
    "                x_batch=x_batch.to(device)\n",
    "                y_batch=y_batch.to(device)\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred,y_batch)\n",
    "                loss_hist_val[epoch] += loss.item()*y_batch.size(0)\n",
    "                is_correct=(torch.argmax(pred,dim=1) == y_batch).float()\n",
    "                acc_hist_val[epoch] += is_correct.sum()\n",
    "            loss_hist_val[epoch] /= len(dl_val.dataset)\n",
    "            acc_hist_val[epoch] /= len(dl_val.dataset)\n",
    "        \n",
    "            print(f' Epoch {epoch+1} ---- train accuracy: {acc_hist_train[epoch]:.4f} ---- val accuracy: {acc_hist_val[epoch]:.4f}')\n",
    "        \n",
    "    return loss_hist_train,loss_hist_val,acc_hist_train,acc_hist_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d72f980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:49.470916Z",
     "iopub.status.busy": "2022-12-19T16:24:49.469574Z",
     "iopub.status.idle": "2022-12-19T16:24:49.474172Z",
     "shell.execute_reply": "2022-12-19T16:24:49.473354Z"
    },
    "papermill": {
     "duration": 0.014134,
     "end_time": "2022-12-19T16:24:49.476050",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.461916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2a1bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:24:49.490947Z",
     "iopub.status.busy": "2022-12-19T16:24:49.490315Z",
     "iopub.status.idle": "2022-12-19T16:27:18.402346Z",
     "shell.execute_reply": "2022-12-19T16:27:18.400648Z"
    },
    "papermill": {
     "duration": 148.92228,
     "end_time": "2022-12-19T16:27:18.405154",
     "exception": false,
     "start_time": "2022-12-19T16:24:49.482874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 ---- train accuracy: 0.9224 ---- val accuracy: 0.9552\n",
      " Epoch 2 ---- train accuracy: 0.9706 ---- val accuracy: 0.9774\n",
      " Epoch 3 ---- train accuracy: 0.9849 ---- val accuracy: 0.9819\n",
      " Epoch 4 ---- train accuracy: 0.9877 ---- val accuracy: 0.9857\n",
      " Epoch 5 ---- train accuracy: 0.9889 ---- val accuracy: 0.9850\n",
      " Epoch 6 ---- train accuracy: 0.9914 ---- val accuracy: 0.9898\n",
      " Epoch 7 ---- train accuracy: 0.9921 ---- val accuracy: 0.9833\n",
      " Epoch 8 ---- train accuracy: 0.9919 ---- val accuracy: 0.9860\n",
      " Epoch 9 ---- train accuracy: 0.9922 ---- val accuracy: 0.9886\n",
      " Epoch 10 ---- train accuracy: 0.9934 ---- val accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "hist = train(model,num_epochs,dl_train,dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ef65a",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2022-12-19T16:27:18.420662",
     "exception": false,
     "start_time": "2022-12-19T16:27:18.413448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb44ce",
   "metadata": {
    "papermill": {
     "duration": 0.007093,
     "end_time": "2022-12-19T16:27:18.435139",
     "exception": false,
     "start_time": "2022-12-19T16:27:18.428046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load in sample_submission.csv as a dataframe, in which we will fill in our predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e873425a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:18.451018Z",
     "iopub.status.busy": "2022-12-19T16:27:18.450727Z",
     "iopub.status.idle": "2022-12-19T16:27:18.475628Z",
     "shell.execute_reply": "2022-12-19T16:27:18.474587Z"
    },
    "papermill": {
     "duration": 0.03532,
     "end_time": "2022-12-19T16:27:18.477820",
     "exception": false,
     "start_time": "2022-12-19T16:27:18.442500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      0\n",
       "1            2      0\n",
       "2            3      0\n",
       "3            4      0\n",
       "4            5      0\n",
       "...        ...    ...\n",
       "27995    27996      0\n",
       "27996    27997      0\n",
       "27997    27998      0\n",
       "27998    27999      0\n",
       "27999    28000      0\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73716079",
   "metadata": {
    "papermill": {
     "duration": 0.007298,
     "end_time": "2022-12-19T16:27:18.492739",
     "exception": false,
     "start_time": "2022-12-19T16:27:18.485441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert ds_test data to a PyTorch tensor of shape (1,28,28) and send it to device, where the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1accaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:18.508667Z",
     "iopub.status.busy": "2022-12-19T16:27:18.508399Z",
     "iopub.status.idle": "2022-12-19T16:27:26.245154Z",
     "shell.execute_reply": "2022-12-19T16:27:26.244140Z"
    },
    "papermill": {
     "duration": 7.747469,
     "end_time": "2022-12-19T16:27:26.247659",
     "exception": false,
     "start_time": "2022-12-19T16:27:18.500190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.array([ds_test[x][0].numpy() for x in range(len(ds_test))])\n",
    "X_test = torch.Tensor(X_test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466a125",
   "metadata": {
    "papermill": {
     "duration": 0.007429,
     "end_time": "2022-12-19T16:27:26.263079",
     "exception": false,
     "start_time": "2022-12-19T16:27:26.255650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make the prediction and insert the predicted labels into the sub_df.  Then export our submission file as .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0441ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:26.279946Z",
     "iopub.status.busy": "2022-12-19T16:27:26.279103Z",
     "iopub.status.idle": "2022-12-19T16:27:26.292276Z",
     "shell.execute_reply": "2022-12-19T16:27:26.291410Z"
    },
    "papermill": {
     "duration": 0.023798,
     "end_time": "2022-12-19T16:27:26.294433",
     "exception": false,
     "start_time": "2022-12-19T16:27:26.270635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds=model(X_test).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60ea0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:26.311212Z",
     "iopub.status.busy": "2022-12-19T16:27:26.310347Z",
     "iopub.status.idle": "2022-12-19T16:27:30.309368Z",
     "shell.execute_reply": "2022-12-19T16:27:30.308395Z"
    },
    "papermill": {
     "duration": 4.009522,
     "end_time": "2022-12-19T16:27:30.311655",
     "exception": false,
     "start_time": "2022-12-19T16:27:26.302133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k in range(len(preds)):\n",
    "    sub_df.Label.iloc[k]=int(preds[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bbd270d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:30.329966Z",
     "iopub.status.busy": "2022-12-19T16:27:30.328307Z",
     "iopub.status.idle": "2022-12-19T16:27:30.339096Z",
     "shell.execute_reply": "2022-12-19T16:27:30.338096Z"
    },
    "papermill": {
     "duration": 0.021849,
     "end_time": "2022-12-19T16:27:30.341599",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.319750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0024fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:30.357951Z",
     "iopub.status.busy": "2022-12-19T16:27:30.357657Z",
     "iopub.status.idle": "2022-12-19T16:27:30.386316Z",
     "shell.execute_reply": "2022-12-19T16:27:30.385505Z"
    },
    "papermill": {
     "duration": 0.038958,
     "end_time": "2022-12-19T16:27:30.388249",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.349291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('../working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b460b",
   "metadata": {
    "papermill": {
     "duration": 0.007455,
     "end_time": "2022-12-19T16:27:30.403249",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.395794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce85d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:30.419874Z",
     "iopub.status.busy": "2022-12-19T16:27:30.419148Z",
     "iopub.status.idle": "2022-12-19T16:27:30.448132Z",
     "shell.execute_reply": "2022-12-19T16:27:30.447292Z"
    },
    "papermill": {
     "duration": 0.039317,
     "end_time": "2022-12-19T16:27:30.450210",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.410893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model,'mnist_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "439b7603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:30.466798Z",
     "iopub.status.busy": "2022-12-19T16:27:30.466525Z",
     "iopub.status.idle": "2022-12-19T16:27:30.492133Z",
     "shell.execute_reply": "2022-12-19T16:27:30.491307Z"
    },
    "papermill": {
     "duration": 0.035956,
     "end_time": "2022-12-19T16:27:30.494031",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.458075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'mnist_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c063573",
   "metadata": {
    "papermill": {
     "duration": 0.007304,
     "end_time": "2022-12-19T16:27:30.509035",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.501731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Gradio app implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1308a84",
   "metadata": {
    "papermill": {
     "duration": 0.007377,
     "end_time": "2022-12-19T16:27:30.523987",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.516610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code creates an interactive Gradio app, which will ask the user to draw a digit on an in-browser sketchpad and then guess the digit using the model we've trained.  See this link for an implementation hosted on my huggingface account: https://huggingface.co/spaces/etweedy/digits\n",
    "\n",
    "There are several steps to this implementation:\n",
    "1. Write a prediction function which will take in an image from the Gradio sketchpad and make a prediction of the digit using our model.\n",
    "2. Write the code that launchest the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c86ab86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:30.540654Z",
     "iopub.status.busy": "2022-12-19T16:27:30.539914Z",
     "iopub.status.idle": "2022-12-19T16:27:50.537412Z",
     "shell.execute_reply": "2022-12-19T16:27:50.536379Z"
    },
    "papermill": {
     "duration": 20.008501,
     "end_time": "2022-12-19T16:27:50.540064",
     "exception": false,
     "start_time": "2022-12-19T16:27:30.531563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc91020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:50.569596Z",
     "iopub.status.busy": "2022-12-19T16:27:50.568852Z",
     "iopub.status.idle": "2022-12-19T16:27:50.574784Z",
     "shell.execute_reply": "2022-12-19T16:27:50.573731Z"
    },
    "papermill": {
     "duration": 0.025097,
     "end_time": "2022-12-19T16:27:50.577080",
     "exception": false,
     "start_time": "2022-12-19T16:27:50.551983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)[0]\n",
    "    return int(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8abad",
   "metadata": {
    "papermill": {
     "duration": 0.008021,
     "end_time": "2022-12-19T16:27:50.593820",
     "exception": false,
     "start_time": "2022-12-19T16:27:50.585799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code creates a locally hosted version of your web app which you can open and play with in your browser, if you are running this notebook on your local machine.\n",
    "\n",
    "It's easy to share your machine learning project as a Gradio space on huggingface! More info: https://huggingface.co/blog/gradio-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35101ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T16:27:50.611247Z",
     "iopub.status.busy": "2022-12-19T16:27:50.610935Z",
     "iopub.status.idle": "2022-12-19T16:27:54.269203Z",
     "shell.execute_reply": "2022-12-19T16:27:54.268289Z"
    },
    "papermill": {
     "duration": 3.66932,
     "end_time": "2022-12-19T16:27:54.271452",
     "exception": false,
     "start_time": "2022-12-19T16:27:50.602132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = \"Guess that digit\"\n",
    "description = \"Draw your favorite base-10 digit (0-9) and click submit - I'll try to guess what you drew! I do a bit better if you're not too messy and your digit is fairly centered.\"\n",
    "gr.Interface(fn=predict, \n",
    "             inputs=\"sketchpad\",\n",
    "             outputs=\"label\",\n",
    "             title = title,\n",
    "             description = description,\n",
    "              ).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 204.275798,
   "end_time": "2022-12-19T16:27:55.918990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-19T16:24:31.643192",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "baacd7ded0742aa8408bda3ed6ced71320ba4869ece4e05e453d0cf31ed1376f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
